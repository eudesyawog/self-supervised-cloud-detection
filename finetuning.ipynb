{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e17c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import datetime as dt\n",
    "import torch \n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from argparse import ArgumentParser\n",
    "from sslcd import CloudDetectionDataModule\n",
    "from sslcd import ResNet\n",
    "from sslcd import seed_all\n",
    "from sslcd import DelayedUnfreeze\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"\"\n",
    "\n",
    "dataset_name = {\"WHUS2CD\":\"WHUS2-CD+\",\n",
    "                \"CloudSen12\":\"CloudSEN12\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"WHUS2CD\"  #\"CloudSen12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # DataModule Settings\n",
    "    data_dir = dataset_path+f\"/{dataset}\",\n",
    "    seed = 42,\n",
    "    batch_size = 16,\n",
    "    num_workers = 8,\n",
    "    limit_dataset = 0.25, # Fraction of the dataset to use for finetuning (between 0 and 1)\n",
    "    patch_size = 256,\n",
    "    dataset = dataset_name[dataset],\n",
    "    task = \"cloud\",\n",
    "    \n",
    "    # Trainer Settings\n",
    "    devices = 1,\n",
    "    accelerator=\"gpu\",\n",
    "    \n",
    "    # Model Parameters\n",
    "    use_mlp = False,\n",
    "    num_classes = 1,\n",
    "    input_ch = 13,\n",
    "    backbone = \"resnet18\",\n",
    "    segmentation = True,\n",
    "    checkpoint= \"\", # pretraining checkpoint from MoCo or DeepCluster   \n",
    "    \n",
    "    # Optimizer Parameters\n",
    "    optimizer = \"Adam\",\n",
    "    scheduler = \"CosineAnnealingLR\",\n",
    "    momentum = 0.9,\n",
    "    max_epochs = 50,\n",
    "    learning_rate = 0.04\n",
    ")\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = ResNet.add_model_specific_args(parser)\n",
    "parser = CloudDetectionDataModule.add_model_specific_args(parser)\n",
    "\n",
    "args, arg_strings = parser.parse_known_args([], None)\n",
    "for key, value in config.items():\n",
    "    setattr(args, key, value)\n",
    "\n",
    "seed_all(config['seed'])\n",
    "\n",
    "datamodule = CloudDetectionDataModule.from_argparse_args(args)\n",
    "\n",
    "args.classification_head = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(512, 64, kernel_size=3, padding=1),\n",
    "    torch.nn.InstanceNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, config['num_classes'], kernel_size=1)\n",
    ")\n",
    "\n",
    "model = ResNet(**args.__dict__)\n",
    "\n",
    "if \"moco\" in config['checkpoint'].lower():\n",
    "    filter_and_remap = \"encoder_q\"\n",
    "    ssl_framework = \"moco\"\n",
    "elif \"deepcluster\" in config['checkpoint'].lower():\n",
    "    filter_and_remap = \"backbone\"\n",
    "    ssl_framework = \"deepcluster\"\n",
    "\n",
    "model.load_from_checkpoint(config['checkpoint'], filter_and_remap=filter_and_remap)\n",
    "print (\"Weights loaded from pretraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = pl.callbacks.ModelCheckpoint(\n",
    "dirpath=f'experiments/{dataset.lower()}/{ssl_framework}/{config['task']}/ft_{config['limit_dataset']*100:.0f}',\n",
    "    filename=\"{epoch}-{val_acc:.2f}\",\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "early_stopping_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=15)\n",
    "\n",
    "unfreezer = DelayedUnfreeze(backbone_id=\"model\", unfreeze_at_epoch=5, train_frozen_bn=True, reset_lr=7e-3)\n",
    "\n",
    "callbacks = [checkpointer, early_stopping_callback, unfreezer]\n",
    "\n",
    "current_datetime = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logger = TensorBoardLogger(\n",
    "                    save_dir=\"experiments/logs\",\n",
    "                    name = \"tensorboard/\",\n",
    "                    version=f\"{dataset.lower()}_{ssl_framework}_{config['task']}_ft_{config['limit_dataset']*100:.0f}_{current_datetime}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82fbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find learning rate \n",
    "trainer_lr = pl.Trainer.from_argparse_args(args, enable_checkpointing=False, logger=None, auto_lr_find=True)\n",
    "lr_finder = trainer_lr.tune(model, datamodule=datamodule, lr_find_kwargs={\"min_lr\": 1e-7, \"max_lr\": 1e-1})\n",
    "\n",
    "args.learning_rate = lr_finder['lr_find'].suggestion()\n",
    "print (\"Suggested learning rate:\",args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49bed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = pl.Trainer.from_argparse_args(args, enable_checkpointing=True, \n",
    "                                        logger=logger, \n",
    "                                        callbacks=callbacks, \n",
    "                                        auto_lr_find=False\n",
    "                                        )\n",
    "run = trainer.fit(model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
